dbutils.widgets.text("Date","")
input_name=dbutils.widgets.get("Date")
print(input_name)

df=spark.read.csv(f"/Volumes/workspace/default/homework/bookings/bookings_{input_name}.csv", header=True, inferSchema=True)
display(df)

df2=spark.read.csv(f"/Volumes/workspace/default/homework/customers/customers_{input_name}.csv", header=True, inferSchema=True)
display(df2)

def remove_null(df,col_name): 
 return df.filter(col(col_name).isNotNull())
 

df3=remove_null(df,"booking_id")
df4=remove_null(df3,"customer_id")
df5=remove_null(df4,"amount")
display(df5)

df5.write.format("delta").mode("append").saveAsTable("default.bookings2_filtered")

current_df = spark.read.table("default.bookings_filtered")
display(current_df)

current2_df = spark.table("default.bookings2_filtered")
display(current2_df)

merge_df = current_df.join(current2_df, on="booking_id", how="left")  
display(merge_df)